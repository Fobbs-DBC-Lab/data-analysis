{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Analysis Test Playground"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pandas version: 2.2.3\n",
      "NumPy version: 2.0.2\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime as dt\n",
    "import os\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "import glob\n",
    "\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "# This requires Python 3.7 and above\n",
    "print('Pandas version:', pd.__version__)\n",
    "print('NumPy version:', np.__version__)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## File Helping Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CSV File Reader Function\n",
    "\n",
    "Reads multiple CSV files starting with \"FED\" from a directory and combines them into a single DataFrame."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What it does\n",
    "- Scans directory for \"FED*.CSV\" files\n",
    "- Reads each file and adds a `file_num` identifier column\n",
    "- Combines all files into one DataFrame\n",
    "- Converts \"MM:DD:YYYY hh:mm:ss\" to datetime format\n",
    "\n",
    "#### Usage\n",
    "```python\n",
    "# Import and use\n",
    "from your_module import read_csv_files\n",
    "combined_data = read_csv_files(\"/path/to/csv/files\")\n",
    "\n",
    "# Work with results\n",
    "print(f\"Total records: {len(combined_data)}\")\n",
    "```\n",
    "\n",
    "#### Notes\n",
    "- Handles file reading errors gracefully\n",
    "- Returns empty DataFrame if no valid files found\n",
    "- Datetime sorting is available (commented out by default)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_csv_files(file_path):\n",
    "    \"\"\"\n",
    "    Reads CSV files that start with 'FED' and organizes them into a single dataframe with file categories.\n",
    "    \n",
    "    Args:\n",
    "        file_path (str): Path to the directory containing CSV files\n",
    "        \n",
    "    Returns:\n",
    "        pandas.DataFrame: A single dataframe containing data from all FED CSV files\n",
    "    \"\"\"\n",
    "    all_dataframes = []\n",
    "    file_counter = 1  # Initialize counter for file categories\n",
    "\n",
    "    # For all files in folder\n",
    "    for file in os.listdir(file_path):\n",
    "        if file.endswith(\".CSV\") and file.startswith(\"FED\"):\n",
    "            # Read that file into a dataframe\n",
    "            file_path_df = os.path.join(file_path, file)\n",
    "            try:\n",
    "                df = pd.read_csv(file_path_df)\n",
    "                \n",
    "                # Add file category column\n",
    "                df[\"file_num\"] = file_counter\n",
    "                file_counter += 1\n",
    "                \n",
    "                all_dataframes.append(df)\n",
    "            except Exception as e:\n",
    "                print(f\"Error reading file {file}: {e}\")\n",
    "    \n",
    "    if not all_dataframes:\n",
    "        print(\"No valid FED CSV files found in the specified directory.\")\n",
    "        return pd.DataFrame()\n",
    "        \n",
    "    # Create a single dataframe from all files\n",
    "    singular_df = pd.concat(all_dataframes, ignore_index=True)\n",
    "    \n",
    "    # Convert datetime column to datetime type\n",
    "    try:\n",
    "        singular_df[\"MM:DD:YYYY hh:mm:ss\"] = pd.to_datetime(singular_df[\"MM:DD:YYYY hh:mm:ss\"])\n",
    "        # Uncomment the line below to sort by datetime\n",
    "        # singular_df = singular_df.sort_values(by=['MM:DD:YYYY hh:mm:ss'], ascending=True)\n",
    "    except KeyError:\n",
    "        print(\"Warning: 'MM:DD:YYYY hh:mm:ss' column not found. Skipping datetime conversion.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error converting datetime: {e}\")\n",
    "    \n",
    "    return singular_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab Data File Path Setup and Directory File Count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This code defines file path variables for a data analysis project in the Fobbs Lab. \n",
    "- It specifies paths to directories containing mouse experimental data, particularly for the \"Chow Group\" and a specific mouse (M281) with a feeding device (FED004). \n",
    "- It also defines variables for the mouse ID, feeding device ID, and date (February 23, 2025). \n",
    "- Finally, it prints the number of files found in the individual mouse's directory by using the os.listdir() function to count files and displaying the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of files found: \n",
      "39\n"
     ]
    }
   ],
   "source": [
    "\n",
    "MICE_GROUP_PATH ='/Users/kevinmcpherson/github-projects/fobbs-lab/data-analysis/local_files/input/Chow Group/'\n",
    "INDIVIDUAL_MOUSE_PATH = '/Users/kevinmcpherson/github-projects/fobbs-lab/data-analysis/local_files/input/Chow Group/m281_FED004/'\n",
    "SD_ANALYSIS_FILES_PATH = '/Users/kevinmcpherson/github-projects/fobbs-lab/data-analysis/local_files/input/SD Analyses/'\n",
    "MOUSE = 'M281'\n",
    "FED = '_FED004'\n",
    "DATE = '022325'\n",
    "\n",
    "\n",
    "print (\"Number of files found: \")\n",
    "print(len(os.listdir(INDIVIDUAL_MOUSE_PATH)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing FED Device Data Files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This script processes FED (Feeding Experimentation Device) data files by adding two new columns that track the beginning and end dates for each file number in the dataset.\n",
    "\n",
    "### Input Data Structure\n",
    "The script expects a CSV file with the following key columns:\n",
    "- An unnamed index column (first column)\n",
    "- `MM:DD:YYYY hh:mm:ss`: Timestamp column in the format \"M/D/YYYY HH:MM:SS\"\n",
    "- `file_num`: Integer column indicating the file number\n",
    "\n",
    "### New Columns Added\n",
    "The script adds two new columns to the dataset:\n",
    "- `file_begin_date`: The date (MM/DD/YYYY) when each file_num first appears\n",
    "- `file_end_date`: The date (MM/DD/YYYY) when each file_num last appears\n",
    "\n",
    "### Processing Steps\n",
    "1. Reads the CSV file using pandas, setting the unnamed first column as the index\n",
    "2. Converts the \"MM:DD:YYYY hh:mm:ss\" column to datetime format for proper date handling\n",
    "3. Groups the data by file_num to identify:\n",
    "   - First timestamp for each file number (begin_date)\n",
    "   - Last timestamp for each file number (end_date)\n",
    "4. Creates new columns mapping these dates back to the original dataframe\n",
    "5. Formats dates in MM/DD/YYYY format\n",
    "6. Saves the processed data to a new CSV file\n",
    "\n",
    "### Usage\n",
    "```python\n",
    "input_file = \"SD Analyses M281 FED004.csv\"\n",
    "output_file = \"SD Analyses M281 FED004_processed.csv\"\n",
    "processed_df = process_fed_dates(input_file, output_file)\n",
    "```\n",
    "\n",
    "### Output\n",
    "The script creates a new CSV file with all original columns plus:\n",
    "- file_begin_date\n",
    "- file_end_date\n",
    "\n",
    "It also prints:\n",
    "- A sample of the processed data (first 5 rows)\n",
    "- A summary showing the date ranges for each file number\n",
    "\n",
    "Note: The original timestamp format is preserved in the \"MM:DD:YYYY hh:mm:ss\" column, while the new date columns are formatted as MM/DD/YYYY for clarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_fed_dates(input_file, output_file):\n",
    "    \"\"\"\n",
    "    Process FED device CSV file to add file_begin_date and file_end_date columns.\n",
    "\n",
    "    Parameters:\n",
    "    input_file (str): Path to input CSV file\n",
    "    output_file (str): Path to save the processed CSV file\n",
    "    \"\"\"\n",
    "    # Read the CSV file\n",
    "    # Note: the first column is unnamed and just an index, so we'll use it as the index\n",
    "    df = pd.read_csv(input_file, index_col=0)\n",
    "\n",
    "    # Convert datetime column to datetime type\n",
    "    df['MM:DD:YYYY hh:mm:ss'] = pd.to_datetime(df['MM:DD:YYYY hh:mm:ss'])\n",
    "\n",
    "    # Group by file_num and get first and last dates\n",
    "    file_dates = df.groupby('file_num').agg({\n",
    "        'MM:DD:YYYY hh:mm:ss': ['first', 'last']\n",
    "    })\n",
    "\n",
    "    # Rename columns for clarity\n",
    "    file_dates.columns = ['begin_date', 'end_date']\n",
    "\n",
    "    # Convert to dictionary for mapping\n",
    "    begin_dates = file_dates['begin_date'].to_dict()\n",
    "    end_dates = file_dates['end_date'].to_dict()\n",
    "\n",
    "    # Add new columns to original dataframe\n",
    "    df['file_begin_date'] = df['file_num'].map(begin_dates).dt.strftime('%m/%d/%Y')\n",
    "    df['file_end_date'] = df['file_num'].map(end_dates).dt.strftime('%m/%d/%Y')\n",
    "\n",
    "    # Save to new CSV file\n",
    "    df.to_csv(output_file)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CSV Reader Function Explanation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This function processes multiple CSV files from a specified directory and combines them into a single pandas DataFrame. Here's what it does:\n",
    "\n",
    "1. **Filters Files**: It only processes files that:\n",
    "   - Have a `.CSV` extension\n",
    "   - Start with `FED` in their filename\n",
    "\n",
    "2. **Adds Metadata**: Each file's data is tagged with a sequential number (`file_num`) to track which file the data came from.\n",
    "\n",
    "3. **Combines Data**: All individual DataFrames are concatenated into a single DataFrame.\n",
    "\n",
    "4. **Date Processing**: It converts a date-time column named `MM:DD:YYYY hh:mm:ss` to pandas datetime format for better date handling.\n",
    "\n",
    "5. **Optional Sorting**: Contains a commented-out line that would sort the data by the date-time column if uncommented.\n",
    "\n",
    "This function is useful for analyzing data spread across multiple CSV files that follow a similar format, particularly for time series data from multiple collection periods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_csv_files(file_path):\n",
    "    \"\"\"\n",
    "    Reads CSV files that start with 'FED' from a directory and combines them \n",
    "    into a single dataframe with file numbering.\n",
    "    \n",
    "    Args:\n",
    "        file_path (str): Path to the directory containing CSV files\n",
    "        \n",
    "    Returns:\n",
    "        pandas.DataFrame: Combined dataframe with all CSV data and file numbers\n",
    "    \"\"\"\n",
    "    all_dataframes = []\n",
    "    file_counter = 1\n",
    "    \n",
    "    # Iterate through all files in the specified directory\n",
    "    for file in os.listdir(file_path):\n",
    "        # Process only CSV files that start with \"FED\"\n",
    "        if file.endswith(\".CSV\") and file.startswith(\"FED\"):\n",
    "            # Construct the full file path\n",
    "            file_path_df = os.path.join(file_path, file)\n",
    "            \n",
    "            # Read the CSV into a dataframe\n",
    "            df = pd.read_csv(file_path_df)\n",
    "            \n",
    "            # Add a file number identifier column\n",
    "            df['file_num'] = file_counter\n",
    "            file_counter += 1\n",
    "            \n",
    "            # Add to our collection\n",
    "            all_dataframes.append(df)\n",
    "    \n",
    "    # Exit early if no files were found\n",
    "    if not all_dataframes:\n",
    "        return pd.DataFrame()\n",
    "        \n",
    "    # Combine all dataframes into one\n",
    "    singular_df = pd.concat(all_dataframes)\n",
    "    \n",
    "    # Convert date-time column to datetime type\n",
    "    singular_df['MM:DD:YYYY hh:mm:ss'] = pd.to_datetime(singular_df['MM:DD:YYYY hh:mm:ss'])\n",
    "    \n",
    "    # Uncomment the below line to sort by date-time\n",
    "    # singular_df = singular_df.sort_values(by=['MM:DD:YYYY hh:mm:ss'], ascending=True)\n",
    "    \n",
    "    return singular_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Usage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make concatentated file for `input_file` field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MM:DD:YYYY hh:mm:ss</th>\n",
       "      <th>Library_Version</th>\n",
       "      <th>Session_type</th>\n",
       "      <th>Device_Number</th>\n",
       "      <th>Battery_Voltage</th>\n",
       "      <th>Motor_Turns</th>\n",
       "      <th>FR</th>\n",
       "      <th>Event</th>\n",
       "      <th>Active_Poke</th>\n",
       "      <th>Left_Poke_Count</th>\n",
       "      <th>Right_Poke_Count</th>\n",
       "      <th>Pellet_Count</th>\n",
       "      <th>Block_Pellet_Count</th>\n",
       "      <th>Retrieval_Time</th>\n",
       "      <th>InterPelletInterval</th>\n",
       "      <th>Poke_Time</th>\n",
       "      <th>file_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-04-10 12:44:25</td>\n",
       "      <td>1.14.0</td>\n",
       "      <td>ClosedEcon</td>\n",
       "      <td>4</td>\n",
       "      <td>3.83</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>Left</td>\n",
       "      <td>Left</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.22</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-04-10 12:44:33</td>\n",
       "      <td>1.14.0</td>\n",
       "      <td>ClosedEcon</td>\n",
       "      <td>4</td>\n",
       "      <td>3.83</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Pellet</td>\n",
       "      <td>Left</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.89</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-04-10 12:45:53</td>\n",
       "      <td>1.14.0</td>\n",
       "      <td>ClosedEcon</td>\n",
       "      <td>4</td>\n",
       "      <td>3.83</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>Left</td>\n",
       "      <td>Left</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.17</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-04-10 12:45:57</td>\n",
       "      <td>1.14.0</td>\n",
       "      <td>ClosedEcon</td>\n",
       "      <td>4</td>\n",
       "      <td>3.83</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>Left</td>\n",
       "      <td>Left</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.05</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024-04-10 12:46:00</td>\n",
       "      <td>1.14.0</td>\n",
       "      <td>ClosedEcon</td>\n",
       "      <td>4</td>\n",
       "      <td>3.83</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>Pellet</td>\n",
       "      <td>Left</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.53</td>\n",
       "      <td>88.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2024-04-10 12:47:24</td>\n",
       "      <td>1.14.0</td>\n",
       "      <td>ClosedEcon</td>\n",
       "      <td>4</td>\n",
       "      <td>3.83</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>Left</td>\n",
       "      <td>Left</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2024-04-10 12:50:32</td>\n",
       "      <td>1.14.0</td>\n",
       "      <td>ClosedEcon</td>\n",
       "      <td>4</td>\n",
       "      <td>3.83</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>Left</td>\n",
       "      <td>Left</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.21</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2024-04-10 12:50:34</td>\n",
       "      <td>1.14.0</td>\n",
       "      <td>ClosedEcon</td>\n",
       "      <td>4</td>\n",
       "      <td>3.83</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>Left</td>\n",
       "      <td>Left</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.13</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2024-04-10 12:50:35</td>\n",
       "      <td>1.14.0</td>\n",
       "      <td>ClosedEcon</td>\n",
       "      <td>4</td>\n",
       "      <td>3.83</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>Pellet</td>\n",
       "      <td>Left</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.42</td>\n",
       "      <td>275.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2024-04-10 12:54:14</td>\n",
       "      <td>1.14.0</td>\n",
       "      <td>ClosedEcon</td>\n",
       "      <td>4</td>\n",
       "      <td>3.83</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>Right</td>\n",
       "      <td>Left</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.05</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  MM:DD:YYYY hh:mm:ss Library_Version Session_type  Device_Number  \\\n",
       "0 2024-04-10 12:44:25          1.14.0   ClosedEcon              4   \n",
       "1 2024-04-10 12:44:33          1.14.0   ClosedEcon              4   \n",
       "2 2024-04-10 12:45:53          1.14.0   ClosedEcon              4   \n",
       "3 2024-04-10 12:45:57          1.14.0   ClosedEcon              4   \n",
       "4 2024-04-10 12:46:00          1.14.0   ClosedEcon              4   \n",
       "5 2024-04-10 12:47:24          1.14.0   ClosedEcon              4   \n",
       "6 2024-04-10 12:50:32          1.14.0   ClosedEcon              4   \n",
       "7 2024-04-10 12:50:34          1.14.0   ClosedEcon              4   \n",
       "8 2024-04-10 12:50:35          1.14.0   ClosedEcon              4   \n",
       "9 2024-04-10 12:54:14          1.14.0   ClosedEcon              4   \n",
       "\n",
       "   Battery_Voltage  Motor_Turns  FR   Event Active_Poke  Left_Poke_Count  \\\n",
       "0             3.83          NaN   1    Left        Left                1   \n",
       "1             3.83          3.0   1  Pellet        Left                1   \n",
       "2             3.83          NaN   2    Left        Left                2   \n",
       "3             3.83          NaN   2    Left        Left                3   \n",
       "4             3.83          1.0   2  Pellet        Left                3   \n",
       "5             3.83          NaN   3    Left        Left                4   \n",
       "6             3.83          NaN   3    Left        Left                5   \n",
       "7             3.83          NaN   3    Left        Left                6   \n",
       "8             3.83          1.0   3  Pellet        Left                6   \n",
       "9             3.83          NaN   4   Right        Left                6   \n",
       "\n",
       "   Right_Poke_Count  Pellet_Count  Block_Pellet_Count Retrieval_Time  \\\n",
       "0                 0             0                   0            NaN   \n",
       "1                 0             1                   1           1.89   \n",
       "2                 0             1                   1            NaN   \n",
       "3                 0             1                   1            NaN   \n",
       "4                 0             2                   2           1.53   \n",
       "5                 0             2                   2            NaN   \n",
       "6                 0             2                   2            NaN   \n",
       "7                 0             2                   2            NaN   \n",
       "8                 0             3                   3           0.42   \n",
       "9                 1             3                   3            NaN   \n",
       "\n",
       "   InterPelletInterval  Poke_Time  file_num  \n",
       "0                  NaN       0.22         1  \n",
       "1                  NaN        NaN         1  \n",
       "2                  NaN       0.17         1  \n",
       "3                  NaN       0.05         1  \n",
       "4                 88.0        NaN         1  \n",
       "5                  NaN       0.11         1  \n",
       "6                  NaN       0.21         1  \n",
       "7                  NaN       0.13         1  \n",
       "8                275.0        NaN         1  \n",
       "9                  NaN       0.05         1  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read and concatenate all FED CSV files from the individual mouse directory\n",
    "# INDIVIDUAL_MOUSE_PATH should contain the specific FED folder for the mouse being analyzed\n",
    "concatenated_dataframe = read_csv_files(INDIVIDUAL_MOUSE_PATH)\n",
    "\n",
    "# Define the specific output path for saving the concatenated data\n",
    "# This will save the file in the specified directory with a formatted filename\n",
    "output_path = \"/Users/kevinmcpherson/github-projects/fobbs-lab/data-analysis/local_files/output\"\n",
    "\n",
    "# Construct the full output filename with mouse ID, FED device number, and date\n",
    "output_filename = f\"{MOUSE}_{FED}_concat1_{DATE}.csv\"\n",
    "\n",
    "# Combine the path and filename for the complete file location\n",
    "output_file_path = os.path.join(output_path, output_filename)\n",
    "\n",
    "# Save the concatenated data to the specified file path\n",
    "concatenated_dataframe.to_csv(output_file_path)\n",
    "\n",
    "# Display the first 10 rows of the concatenated dataframe for verification\n",
    "concatenated_dataframe.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing complete. New file saved as: /Users/kevinmcpherson/github-projects/fobbs-lab/data-analysis/local_files/output/M281__FED004_concat2_022325.csv\n",
      "\n",
      "Sample of processed data (first 5 rows):\n",
      "   file_num MM:DD:YYYY hh:mm:ss file_begin_date file_end_date\n",
      "0         1 2024-04-10 12:44:25      04/10/2024    04/11/2024\n",
      "1         1 2024-04-10 12:44:33      04/10/2024    04/11/2024\n",
      "2         1 2024-04-10 12:45:53      04/10/2024    04/11/2024\n",
      "3         1 2024-04-10 12:45:57      04/10/2024    04/11/2024\n",
      "4         1 2024-04-10 12:46:00      04/10/2024    04/11/2024\n",
      "\n",
      "Summary of file number date ranges:\n",
      "         file_begin_date file_end_date\n",
      "file_num                              \n",
      "1             04/10/2024    04/11/2024\n",
      "2             04/11/2024    04/12/2024\n",
      "3             03/28/2024    03/29/2024\n",
      "4             03/29/2024    03/30/2024\n",
      "5             04/24/2024    04/25/2024\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    input_file = '/Users/kevinmcpherson/github-projects/fobbs-lab/data-analysis/local_files/output/M281__FED004_concat1_022325.csv'\n",
    "    output_file = '/Users/kevinmcpherson/github-projects/fobbs-lab/data-analysis/local_files/output/M281__FED004_concat2_022325.csv'\n",
    "\n",
    "    processed_df = process_fed_dates(input_file, output_file)\n",
    "    print(\"Processing complete. New file saved as:\", output_file)\n",
    "\n",
    "    # Display sample of processed data\n",
    "    print(\"\\nSample of processed data (first 5 rows):\")\n",
    "    print(processed_df[['file_num', 'MM:DD:YYYY hh:mm:ss', 'file_begin_date', 'file_end_date']].head())\n",
    "\n",
    "    # Print summary of file numbers and their date ranges\n",
    "    summary = processed_df.groupby('file_num').agg({\n",
    "        'file_begin_date': 'first',\n",
    "        'file_end_date': 'first'\n",
    "    })\n",
    "    print(\"\\nSummary of file number date ranges:\")\n",
    "    print(summary.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
